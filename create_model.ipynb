{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-26T08:13:39.345666Z","iopub.status.busy":"2023-11-26T08:13:39.345412Z","iopub.status.idle":"2023-11-26T08:13:43.309925Z","shell.execute_reply":"2023-11-26T08:13:43.308992Z","shell.execute_reply.started":"2023-11-26T08:13:39.345643Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import sys\n","import os\n","import time\n","import random \n","import pandas as pd\n","import torch\n","from torch import nn, cuda, optim\n","from torchvision import models,transforms,datasets\n","from torch.utils.data import DataLoader,random_split"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-26T08:13:43.311997Z","iopub.status.busy":"2023-11-26T08:13:43.311588Z","iopub.status.idle":"2023-11-26T08:14:38.478930Z","shell.execute_reply":"2023-11-26T08:14:38.477988Z","shell.execute_reply.started":"2023-11-26T08:13:43.311970Z"},"trusted":true},"outputs":[],"source":["data_dir = './dataset/train'\n","classes = []\n","img_per_class = []\n","\n","for folder in os.listdir(data_dir):    \n","    classes.append(folder)\n","    img_per_class.append(len(os.listdir(f'{data_dir}/{folder}')))\n","\n","num_classes = len(classes)\n","df = pd.DataFrame({'Classes':classes, 'Examples':img_per_class})\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-26T08:14:38.480597Z","iopub.status.busy":"2023-11-26T08:14:38.480314Z","iopub.status.idle":"2023-11-26T08:14:38.494762Z","shell.execute_reply":"2023-11-26T08:14:38.493879Z","shell.execute_reply.started":"2023-11-26T08:14:38.480575Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["class AverageMeter(object):\n","    r\"\"\"Computes and stores the average and current value\n","    \"\"\"\n","    def __init__(self, name, fmt=':f'):\n","        self.name = name\n","        self.fmt = fmt\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","    def __str__(self):\n","        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n","        return fmtstr.format(**self.__dict__)\n","\n","\n","class ProgressMeter(object):\n","    def __init__(self, num_batches, *meters, prefix=\"\"):\n","        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n","        self.meters = meters\n","        self.prefix = prefix\n","\n","    def print(self, batch):\n","        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n","        entries += [str(meter) for meter in self.meters]\n","        print('\\t'.join(entries))\n","\n","    def _get_batch_fmtstr(self, num_batches):\n","        num_digits = len(str(num_batches // 1))\n","        fmt = '{:' + str(num_digits) + 'd}'\n","        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n","\n","\n","def accuracy(output, target, topk=(1,)):\n","    r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\n","    \"\"\"\n","    with torch.no_grad():\n","        maxk = max(topk)\n","        batch_size = target.size(0)\n","\n","        # _, pred = output.topk(maxk, 1, True, True)\n","        # pred = pred.t()\n","        # correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        # faster topk (ref: https://github.com/pytorch/pytorch/issues/22812)\n","        _, idx = output.sort(descending=True)\n","        pred = idx[:,:maxk]\n","        pred = pred.t()\n","        correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        res = []\n","        for k in topk:\n","            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n","            res.append(correct_k.mul_(100.0 / batch_size))\n","        return res"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2023-11-26T08:14:38.497032Z","iopub.status.busy":"2023-11-26T08:14:38.496730Z","iopub.status.idle":"2023-11-26T08:14:43.122894Z","shell.execute_reply":"2023-11-26T08:14:43.121865Z","shell.execute_reply.started":"2023-11-26T08:14:38.497002Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["import timm\n","torch.manual_seed(1557)\n","\n","_model = timm.create_model(\"efficientnet_b0\", pretrained=True)\n","\n","model = nn.Sequential(\n","    _model,\n","    nn.BatchNorm1d(1000),\n","    nn.ReLU(),\n","    nn.Dropout(),\n","    nn.Linear(1000, num_classes),\n",")\n","\n","pytorch_total_params = sum(p.numel() for p in model.parameters())\n","\n","device = torch.device('cuda:0' if cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","print(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-26T08:14:43.124545Z","iopub.status.busy":"2023-11-26T08:14:43.124191Z","iopub.status.idle":"2023-11-26T08:14:43.132613Z","shell.execute_reply":"2023-11-26T08:14:43.131152Z","shell.execute_reply.started":"2023-11-26T08:14:43.124512Z"},"trusted":true},"outputs":[],"source":["train_transform = transforms.Compose([\n","                                      transforms.Resize(256),\n","                                      transforms.CenterCrop(224),\n","                                      transforms.RandomResizedCrop(224, scale=(0.8, 1.0), ratio=(0.7, 1.3)),\n","                                      transforms.RandomHorizontalFlip(),\n","                                      transforms.RandomRotation(60),\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n","                                      ])\n","\n","val_transform = transforms.Compose([\n","                                      transforms.Resize(256),\n","                                      transforms.CenterCrop(224),\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n","                                    ])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-26T08:14:43.134283Z","iopub.status.busy":"2023-11-26T08:14:43.133907Z","iopub.status.idle":"2023-11-26T08:14:44.558178Z","shell.execute_reply":"2023-11-26T08:14:44.557247Z","shell.execute_reply.started":"2023-11-26T08:14:43.134248Z"},"trusted":true},"outputs":[],"source":["data = datasets.ImageFolder(data_dir)\n","train_size = int(len(data)*0.9)\n","val_size = int((len(data)-train_size))\n","\n","# Using Sklearn to stratified split in ImageFolder Dataset.\n","# https://linuxtut.com/en/c6023453e00bfead9e9f/\n","\n","from sklearn.model_selection import train_test_split\n","\n","train_indices, val_indices = train_test_split(\n","    list(range(len(data.targets))), \n","    train_size=train_size, # train_size=0.95\n","    test_size=val_size, # val_size=0.05\n","    stratify=data.targets,\n","    random_state=1557,\n",")\n","train_data = torch.utils.data.Subset(data, train_indices)\n","val_data = torch.utils.data.Subset(data, val_indices)\n","\n","print(f'train size: {len(train_data)}\\nval size: {len(val_data)}')\n","\n","train_data.dataset.transform = train_transform\n","val_data.dataset.transform = val_transform\n","batch_size = 64\n","num_workers = 1\n","train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True,num_workers=num_workers)\n","val_loader = DataLoader(val_data,batch_size=batch_size,shuffle=True,num_workers=num_workers)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-26T08:16:06.702458Z","iopub.status.busy":"2023-11-26T08:16:06.702073Z","iopub.status.idle":"2023-11-26T08:16:07.524209Z","shell.execute_reply":"2023-11-26T08:16:07.523253Z","shell.execute_reply.started":"2023-11-26T08:16:06.702428Z"},"trusted":true},"outputs":[],"source":["train_distribution_ = np.array(data.targets)[train_indices]\n","val_distribution_ = np.array(data.targets)[val_indices]\n","\n","train_distribution = np.zeros(num_classes, dtype=int)\n","val_distribution = np.zeros(num_classes, dtype=int)\n","\n","for i in train_distribution_:\n","  train_distribution[i]+=1\n","\n","for i in val_distribution_:\n","  val_distribution[i]+=1\n","\n","plt.figure(figsize=(25, 8))\n","for col_idx, bins_ in enumerate([train_distribution, val_distribution, train_distribution + val_distribution]):\n","  plt.subplot(1, 3, col_idx + 1)\n","  plt.plot(range(num_classes), bins_)\n","  plt.title([\"train\", \"val\", \"total\"][col_idx])\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-26T08:16:07.526105Z","iopub.status.busy":"2023-11-26T08:16:07.525791Z","iopub.status.idle":"2023-11-26T08:16:07.532769Z","shell.execute_reply":"2023-11-26T08:16:07.531630Z","shell.execute_reply.started":"2023-11-26T08:16:07.526063Z"},"trusted":true},"outputs":[],"source":["criterion = nn.CrossEntropyLoss().cuda()\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n","\n","scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-26T08:16:07.547704Z","iopub.status.busy":"2023-11-26T08:16:07.547073Z","iopub.status.idle":"2023-11-26T08:16:07.571999Z","shell.execute_reply":"2023-11-26T08:16:07.571007Z","shell.execute_reply.started":"2023-11-26T08:16:07.547672Z"},"trusted":true},"outputs":[],"source":["from datetime import datetime\n","now = datetime.now() \n","lr_over_time = []\n","\n","def fit(model,criterion,optimizer, scheduler=None, num_epochs=10):\n","    global now, lr_over_time\n","    drive_model_save_path = f'./models/{now.year}_{now.month}_{now.day}_{now.hour}_{now.minute}/'\n","\n","    print_freq = 250\n","    start = time.time()\n","    best_model = model.state_dict()\n","    best_acc = 0\n","    train_loss_over_time = []\n","    val_loss_over_time = []\n","    train_acc_over_time = []\n","    val_acc_over_time = []\n","    \n","    for epoch in range(num_epochs):\n","        \n","        print(\"\\n----- epoch: {}, lr: {} -----\".format(epoch, optimizer.param_groups[0][\"lr\"]))\n","        batch_time = AverageMeter('Time', ':6.3f')\n","        acc = AverageMeter('Accuracy', ':.4e')\n","        progress = ProgressMeter(len(train_loader), batch_time, acc, prefix=\"Epoch: [{}]\".format(epoch))\n","\n","        for phase in ['train','val']:\n","            \n","            if phase == 'train':\n","                data_loader = train_loader\n","                model.train()                    # set the model to train mode\n","                end = time.time()\n","\n","            else:\n","                data_loader = val_loader\n","                model.eval()                    # set the model to evaluate mode\n","                end = time.time()\n","            \n","                \n","            running_loss = 0.0\n","            running_corrects = 0.0\n","            \n","            # iterate over the data\n","            for i,(inputs,labels) in enumerate(data_loader):\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","                \n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","                \n","                # forward\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _,pred = torch.max(outputs,dim=1)\n","                    loss = criterion(outputs,labels)\n","                    \n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","                        \n","                        if scheduler is not None and isinstance(scheduler, torch.optim.lr_scheduler.OneCycleLR): # IF SCHEDULER IS ONE CYCLE\n","                            lr_over_time.append(scheduler.get_last_lr()[0])\n","                            if i % print_freq == 0:\n","                                print(f'Curr batch lr = {scheduler.get_last_lr()[0]}')\n","                            scheduler.step()\n","                \n","                # calculating the loss and accuracy\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(pred == labels.data)\n","\n","                epoch_acc = (running_corrects.double()/len(train_data)).cpu().numpy()\n","                acc.update(epoch_acc.item(), inputs.size(0))\n","                \n","                if phase == 'train':                          \n","                    batch_time.update(time.time() - end)\n","                    end = time.time()\n","\n","                    if i % print_freq == 0:\n","                        progress.print(i)\n","                \n","\n","            if phase == 'train':\n","                epoch_loss = running_loss/len(train_data)\n","                train_loss_over_time.append(epoch_loss)\n","                epoch_acc = (running_corrects.double()/len(train_data)).cpu().numpy()\n","                train_acc_over_time.append(epoch_acc)\n","\n","\n","            else:\n","                epoch_loss = running_loss/len(val_data)\n","                val_loss_over_time.append(epoch_loss)\n","                epoch_acc = (running_corrects.double()/len(val_data)).cpu().numpy()\n","                val_acc_over_time.append(epoch_acc)\n","          \n","\n","            print(f'{phase} loss: {epoch_loss:.3f}, acc: {epoch_acc:.3f}')\n","\n","            if not os.path.exists(drive_model_save_path):\n","                  os.makedirs(drive_model_save_path)\n","            \n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                \n","                torch.save(model, drive_model_save_path + f'model_best.pt')\n","                # torch.save(model.state_dict(), drive_model_save_path + f'model_best.pt')\n","            \n","            torch.save(model, drive_model_save_path + 'model_latest.pt')\n","            # torch.save(model.state_dict(), drive_model_save_path + 'model_latest.pt')\n","            \n","\n","        print('-'*60)\n","        if scheduler is not None and not isinstance(scheduler, torch.optim.lr_scheduler.OneCycleLR): # IF SCHEDULER IS NOT ONE CYCLE\n","            print(f\"Current epoch #{epoch+1} ended with lr: {scheduler.get_last_lr()[0]}\")\n","            lr_over_time.append(scheduler.get_last_lr()[0])\n","            scheduler.step()\n","            \n","    print('\\n') \n","    elapsed_time = time.time() - start\n","    print('==> {:.2f} seconds to train this epoch\\n'.format(elapsed_time))\n","    print(f'best accuracy: {best_acc:.3f}')\n","\n","\n","    # load best model weights\n","    model.load_state_dict(best_model)\n","    loss = {'train':train_loss_over_time, 'val':val_loss_over_time}\n","    acc = {'train':train_acc_over_time, 'val':val_acc_over_time}\n","\n","    return model,loss, acc"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-26T08:16:07.573513Z","iopub.status.busy":"2023-11-26T08:16:07.573202Z"},"trusted":true},"outputs":[],"source":["epochs = 10\n","\n","history, loss, acc = fit(model, criterion, optimizer, scheduler=scheduler, num_epochs = epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# plotting the loss and accuracy curve for each phase\n","train_loss = loss['train']\n","val_loss = loss['val']\n","train_acc = acc['train']\n","val_acc = acc['val']\n","\n","epochs_range = range(epochs)\n","plt.figure(figsize=(20,10))\n","\n","plt.subplot(1,2,1)\n","plt.ylim(0,10)\n","plt.xlim(0,30)\n","plt.plot(epochs_range, train_loss, label='train_loss')\n","plt.plot(epochs_range, val_loss, label='val_loss')\n","plt.legend(loc=0)\n","plt.title('Loss')\n","\n","plt.subplot(1,2,2)\n","plt.plot(epochs_range, train_acc ,label='train_acc')\n","plt.plot(epochs_range, val_acc, label='val_acc')\n","plt.legend(loc=0)\n","plt.ylim(0,1)\n","plt.xlim(0,30)\n","plt.title('Accuracy')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["if scheduler is not None:\n","    if isinstance(scheduler, torch.optim.lr_scheduler.OneCycleLR):\n","        plt.plot(range(epochs * len(train_loader)), lr_over_time, label=\"learning rate\")\n","    else:\n","        plt.plot(epochs_range, lr_over_time, label=\"learning rate\")\n","    plt.title(\"lr over time\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":534640,"sourceId":5468571,"sourceType":"datasetVersion"}],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
